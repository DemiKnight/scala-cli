"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[2293],{9589:function(a,e,n){n.r(e),n.d(e,{contentTitle:function(){return o},default:function(){return m},frontMatter:function(){return l},metadata:function(){return i},toc:function(){return u}});var t=n(3117),r=n(102),p=(n(7294),n(3905)),s=n(9705),c=["components"],l={},o="Experimental Spark features",i={type:"mdx",permalink:"/spark",source:"@site/src/pages/spark.md",title:"Experimental Spark features",description:"Packaging",frontMatter:{}},u=[{value:"Packaging",id:"packaging",level:2}],k={toc:u};function m(a){var e=a.components,n=(0,r.Z)(a,c);return(0,p.kt)("wrapper",(0,t.Z)({},k,n,{components:e,mdxType:"MDXLayout"}),(0,p.kt)("h1",{id:"experimental-spark-features"},"Experimental Spark features"),(0,p.kt)("h2",{id:"packaging"},"Packaging"),(0,p.kt)("p",null,"The ",(0,p.kt)("inlineCode",{parentName:"p"},"package")," sub-commands offers to package Scala CLI projects as JARs ready to be passed\nto ",(0,p.kt)("inlineCode",{parentName:"p"},"spark-submit"),", and optimized for it."),(0,p.kt)(s.v,{mdxType:"ChainedSnippets"},(0,p.kt)("pre",null,(0,p.kt)("code",{parentName:"pre",className:"language-scala",metastring:"title=SparkJob.scala",title:"SparkJob.scala"},'//> using lib "org.apache.spark::spark-sql:3.0.3"\n//> using scala "2.12.15"\n\nimport org.apache.spark._\nimport org.apache.spark.sql._\n\nobject SparkJob {\n  def main(args: Array[String]): Unit = {\n    val spark = SparkSession.builder()\n      .appName("Test job")\n      .getOrCreate()\n    import spark.implicits._\n    def sc    = spark.sparkContext\n    val accum = sc.longAccumulator\n    sc.parallelize(1 to 10).foreach(x => accum.add(x))\n    println("Result: " + accum.value)\n  }\n}\n')),(0,p.kt)("pre",null,(0,p.kt)("code",{parentName:"pre",className:"language-bash"},"scala-cli package --spark SparkJob.scala -o spark-job.jar\n")),(0,p.kt)("pre",null,(0,p.kt)("code",{parentName:"pre",className:"language-text"},"Compiling project (Scala 2.12.15, JVM)\nCompiled project (Scala 2.12.15, JVM)\nWrote spark-job.jar\n")),(0,p.kt)("pre",null,(0,p.kt)("code",{parentName:"pre",className:"language-bash"},"spark-submit spark-job.jar\n")),(0,p.kt)("pre",null,(0,p.kt)("code",{parentName:"pre",className:"language-text"},"\u2026\nResult: 55\n\u2026\n"))))}m.isMDXComponent=!0},9705:function(a,e,n){n.d(e,{m:function(){return s},v:function(){return p}});var t=n(7294),r=n(2004);function p(a){var e=a.children;return t.createElement("div",{className:"runnable-command"},e)}function s(a){var e=a.url;return t.createElement(r.Z,{playing:!0,loop:!0,muted:!0,controls:!0,width:"100%",height:"",url:e})}}}]);